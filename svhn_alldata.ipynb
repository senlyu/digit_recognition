{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Import all modules\"\"\"\n",
    "from __future__ import print_function\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from IPython.display import display\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import h5py\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Download the train,test and extra dataset \"\"\"\n",
    "url = 'http://ufldl.stanford.edu/housenumbers/'\n",
    "\n",
    "def maybe_download(filename, force=False):\n",
    "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "  if force or not os.path.exists(filename):\n",
    "    print('Attempting to download:', filename) \n",
    "    filename, _ = urlretrieve(url + filename, filename)\n",
    "    print('\\nDownload Complete!')\n",
    "  statinfo = os.stat(filename)\n",
    "  return filename\n",
    "\n",
    "train_filename = maybe_download('train.tar.gz')\n",
    "test_filename = maybe_download('test.tar.gz')\n",
    "\n",
    "\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train already present - Skipping extraction of train.tar.gz.\n",
      "train\n",
      "test already present - Skipping extraction of test.tar.gz.\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Extract dataset files\"\"\"\n",
    "np.random.seed(133)\n",
    "\n",
    "def maybe_extract(filename, force=False):\n",
    "    root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
    "    if os.path.isdir(root) and not force:\n",
    "        # You may override by setting force=True.\n",
    "        print('%s already present - Skipping extraction of %s.' % (root, filename))\n",
    "    else:\n",
    "        print('Extracting data for %s. This may take a while. Please wait.' % root)\n",
    "        tar = tarfile.open(filename)\n",
    "        sys.stdout.flush()\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "    data_folders = root\n",
    "    print(data_folders)\n",
    "    return data_folders\n",
    "  \n",
    "train_folders = maybe_extract(train_filename)\n",
    "test_folders = maybe_extract(test_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Create a python dictionary for bounded box indormation\"\"\"\n",
    "# The DigitStructFile is just a wrapper around the h5py data.  It basically references \n",
    "#    inf:              The input h5 matlab file\n",
    "#    digitStructName   The h5 ref to all the file names\n",
    "#    digitStructBbox   The h5 ref to all struc data\n",
    "class DigitStructFile:\n",
    "    def __init__(self, inf):\n",
    "        self.inf = h5py.File(inf, 'r')\n",
    "        self.digitStructName = self.inf['digitStruct']['name']\n",
    "        self.digitStructBbox = self.inf['digitStruct']['bbox']\n",
    "\n",
    "# getName returns the 'name' string for for the n(th) digitStruct. \n",
    "    def getName(self,n):\n",
    "        return ''.join([chr(c[0]) for c in self.inf[self.digitStructName[n][0]].value])\n",
    "\n",
    "# bboxHelper handles the coding difference when there is exactly one bbox or an array of bbox. \n",
    "    def bboxHelper(self,attr):\n",
    "        if (len(attr) > 1):\n",
    "            attr = [self.inf[attr.value[j].item()].value[0][0] for j in range(len(attr))]\n",
    "        else:\n",
    "            attr = [attr.value[0][0]]\n",
    "        return attr\n",
    "\n",
    "# getBbox returns a dict of data for the n(th) bbox. \n",
    "    def getBbox(self,n):\n",
    "        bbox = {}\n",
    "        bb = self.digitStructBbox[n].item()\n",
    "        bbox['height'] = self.bboxHelper(self.inf[bb][\"height\"])\n",
    "        bbox['label'] = self.bboxHelper(self.inf[bb][\"label\"])\n",
    "        bbox['left'] = self.bboxHelper(self.inf[bb][\"left\"])\n",
    "        bbox['top'] = self.bboxHelper(self.inf[bb][\"top\"])\n",
    "        bbox['width'] = self.bboxHelper(self.inf[bb][\"width\"])\n",
    "        return bbox\n",
    "    \n",
    "    def getDigitStructure(self,n):\n",
    "        s = self.getBbox(n)\n",
    "        s['name']=self.getName(n)\n",
    "        return s\n",
    "\n",
    "# getAllDigitStructure returns all the digitStruct from the input file.     \n",
    "    def getAllDigitStructure(self):\n",
    "        return [self.getDigitStructure(i) for i in range(len(self.digitStructName))]\n",
    "\n",
    "# Return a restructured version of the dataset (one structure by boxed digit).\n",
    "#\n",
    "#   Return a list of such dicts :\n",
    "#      'filename' : filename of the samples\n",
    "#      'boxes' : list of such dicts (one by digit) :\n",
    "#          'label' : 1 to 9 corresponding digits. 10 for digit '0' in image.\n",
    "#          'left', 'top' : position of bounding box\n",
    "#          'width', 'height' : dimension of bounding box\n",
    "#\n",
    "# Note: We may turn this to a generator, if memory issues arise.\n",
    "    def getAllDigitStructure_ByDigit(self):\n",
    "        pictDat = self.getAllDigitStructure()\n",
    "        result = []\n",
    "        structCnt = 1\n",
    "        for i in range(len(pictDat)):\n",
    "            item = { 'filename' : pictDat[i][\"name\"] }\n",
    "            figures = []\n",
    "            for j in range(len(pictDat[i]['height'])):\n",
    "                figure = {}\n",
    "                figure['height'] = pictDat[i]['height'][j]\n",
    "                figure['label']  = pictDat[i]['label'][j]\n",
    "                figure['left']   = pictDat[i]['left'][j]\n",
    "                figure['top']    = pictDat[i]['top'][j]\n",
    "                figure['width']  = pictDat[i]['width'][j]\n",
    "                figures.append(figure)\n",
    "            structCnt = structCnt + 1\n",
    "            item['boxes'] = figures\n",
    "            result.append(item)\n",
    "        return result\n",
    "    \n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n",
      "{'boxes': [{'width': 23.0, 'top': 29.0, 'label': 2.0, 'left': 77.0, 'height': 32.0}, {'width': 26.0, 'top': 25.0, 'label': 3.0, 'left': 98.0, 'height': 32.0}], 'filename': '2.png'}\n"
     ]
    }
   ],
   "source": [
    "digitFileTrain=DigitStructFile(os.path.join('train','digitStruct.mat'))\n",
    "digitFileTest=DigitStructFile(os.path.join('test','digitStruct.mat'))\n",
    "\n",
    "train_data=digitFileTrain.getAllDigitStructure_ByDigit()\n",
    "test_data=digitFileTest.getAllDigitStructure_ByDigit()\n",
    "\n",
    "\n",
    "print(\"Success\")\n",
    "print(train_data[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getlabel(datas):\n",
    "    tlabel=np.ndarray(shape=[len(datas),5],dtype=np.int32)\n",
    "    tbox=np.ndarray(shape=[len(datas),5,4],dtype=np.float32)\n",
    "    for i in range(len(datas)):\n",
    "        k=int(datas[i]['filename'][0:(len(datas[i]['filename'])-4)])-1\n",
    "        for j in range(5):\n",
    "            if j>=len(datas[i]['boxes']):\n",
    "                tlabel[k,j]=0\n",
    "                tbox[k,j,0]=0\n",
    "                tbox[k,j,1]=0\n",
    "                tbox[k,j,2]=0\n",
    "                tbox[k,j,3]=0\n",
    "            else:\n",
    "                tlabel[k,j]=datas[i]['boxes'][j]['label']\n",
    "                tbox[k,j,0]=datas[i]['boxes'][j]['width']\n",
    "                tbox[k,j,1]=datas[i]['boxes'][j]['top']\n",
    "                tbox[k,j,2]=datas[i]['boxes'][j]['left']\n",
    "                tbox[k,j,3]=datas[i]['boxes'][j]['height']\n",
    "    return tlabel,tbox\n",
    "trainlabel,trainbox=getlabel(train_data)\n",
    "testlabel,testbox=getlabel(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 3 1 0 0]\n",
      " [7 3 1 0 0]\n",
      " [7 9 6 0 0]\n",
      " [5 7 3 0 0]\n",
      " [2 4 0 0 0]]\n",
      "[[[ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]]]\n"
     ]
    }
   ],
   "source": [
    "my_label=np.ndarray(shape=[5,5],dtype=np.int32)\n",
    "\n",
    "my_label[0,:]=[7,3,1,0,0]\n",
    "my_label[1,:]=[7,3,1,0,0]\n",
    "my_label[2,:]=[7,9,6,0,0]\n",
    "my_label[3,:]=[5,7,3,0,0]\n",
    "my_label[4,:]=[2,4,0,0,0]\n",
    "print(my_label)\n",
    "\n",
    "my_box=np.ndarray(shape=[5,5,4],dtype=np.float32)\n",
    "for i1 in range(5):\n",
    "    for i2 in range(5):\n",
    "        for i3 in range(4):\n",
    "            my_box[i1,i2,i3]=0\n",
    "print(my_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Create a pickle file to store processed data\"\"\"\n",
    "pickle_file = 'SVHN_labelboxall.pickle'\n",
    "\n",
    "try:\n",
    "    f = open(pickle_file, 'wb')\n",
    "    save = {\n",
    "        'train_label': trainlabel,\n",
    "        'train_box': trainbox,\n",
    "        'test_label': testlabel,\n",
    "        'test_box': testbox,\n",
    "        \n",
    "      }\n",
    "    pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "except Exception as e:\n",
    "    print('Unable to save data to', pickle_file, ':', e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle_file = 'SVHN_labelboxall.pickle'\n",
    "try:\n",
    "    f = open(pickle_file, 'r')\n",
    "    save = pickle.load(f)\n",
    "    trainlabel=save['train_label']\n",
    "    trainbox=save['train_box']\n",
    "    testlabel=save['test_label']\n",
    "    testbox=save['test_box']\n",
    "except Exception as e:\n",
    "    print('Unable to load data to', pickle_file, ':', e)\n",
    "    raise    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 3 1 0 0]\n",
      " [7 3 1 0 0]\n",
      " [7 9 6 0 0]\n",
      " [5 7 3 0 0]\n",
      " [2 4 0 0 0]]\n",
      "[[[ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]]]\n"
     ]
    }
   ],
   "source": [
    "my_label=np.ndarray(shape=[5,5],dtype=np.int32)\n",
    "\n",
    "my_label[0,:]=[7,3,1,0,0]\n",
    "my_label[1,:]=[7,3,1,0,0]\n",
    "my_label[2,:]=[7,9,6,0,0]\n",
    "my_label[3,:]=[5,7,3,0,0]\n",
    "my_label[4,:]=[2,4,0,0,0]\n",
    "print(my_label)\n",
    "\n",
    "my_box=np.ndarray(shape=[5,5,4],dtype=np.float32)\n",
    "for i1 in range(5):\n",
    "    for i2 in range(5):\n",
    "        for i3 in range(4):\n",
    "            my_box[i1,i2,i3]=0\n",
    "print(my_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000.png\n",
      "33402\n",
      "/media/senlyu/Project/digit_recognition\n"
     ]
    }
   ],
   "source": [
    "# load and resize the pictures to 32*32\n",
    "\n",
    "pic_dir=os.getcwd()\n",
    "def getpics(filedir):\n",
    "    data_folders=[os.path.join(filedir,x) for x in sorted(os.listdir(filedir))]\n",
    "    return data_folders\n",
    "train_pic=getpics(pic_dir+'/train')\n",
    "test_pic=getpics(pic_dir+'/test')\n",
    "my_pic=getpics(pic_dir+'/mydata')\n",
    "#sample_pic=getpics(pic_dir+'/sample')\n",
    "print(os.path.basename(train_pic[3]))\n",
    "print(len(train_pic))\n",
    "print(pic_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1576.59863687\n",
      "742.698364019\n",
      "87.8554930687\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Get all the images\"\"\"\n",
    "\n",
    "image_size=64\n",
    "\n",
    "pixel_depth=255.0\n",
    "color_channels=3\n",
    "\n",
    "def imageave(data,x,y,xl,yl,k):\n",
    "    #c=data[x,y,k]\n",
    "    c=0.0\n",
    "    if xl==0 and yl==0:\n",
    "        c=data[x,y,k]\n",
    "    elif xl==0:\n",
    "        for i in range(yl):\n",
    "            c+=data[x,y+i,k]\n",
    "        c=c/yl\n",
    "    elif yl==0:\n",
    "        for i in range(xl):\n",
    "            c+=data[x+i,y,k]\n",
    "        c=c/x1\n",
    "    else:\n",
    "        for i in range(xl):\n",
    "            for j in range(yl):\n",
    "                c+=data[x+i,y+j,k]\n",
    "        c=c/(xl*yl)\n",
    "        \n",
    "    c=(c-pixel_depth/2)/pixel_depth\n",
    "    newdata=c\n",
    "    \n",
    "    return newdata\n",
    "\n",
    "\n",
    "def resizeto32(x,y,data):\n",
    "    x32=x/image_size\n",
    "    y32=y/image_size\n",
    "    newdata=np.ndarray(shape=(image_size,image_size,color_channels),dtype=np.float32)\n",
    "    for i in range(image_size):\n",
    "        for j in range(image_size):\n",
    "            for k in range(color_channels):\n",
    "                newdata[i,j,k]=imageave(data,i*x32,j*y32,x32,y32,k)\n",
    "            \n",
    "    return newdata\n",
    "\n",
    "\n",
    "def loadpics(pics,box):\n",
    "    box1=np.ndarray(shape=[len(box),5,4],dtype=np.float32)\n",
    "    for i in range(len(box)):\n",
    "        for j in range(5):\n",
    "            for k in range(4):\n",
    "                box1[i,j,k]=0\n",
    "    dataset=np.ndarray(shape=(len(pics),image_size,image_size,color_channels),dtype=np.float32)\n",
    "    for pic in pics:\n",
    "        \n",
    "        im = Image.open(pic)\n",
    "        y=im.size[0]\n",
    "        x=im.size[1]\n",
    "        image_data=ndimage.imread(pic).astype(float)\n",
    "        \n",
    "        k=int(os.path.basename(pic)[0:len(os.path.basename(pic))-4])-1\n",
    "\n",
    "        new_data=resizeto32(x,y,image_data)\n",
    "        for j in range(5):\n",
    "             \n",
    "            box1[k,j,0]=box[k,j,0]/im.size[0]*image_size\n",
    "            box1[k,j,1]=box[k,j,1]/im.size[1]*image_size\n",
    "            box1[k,j,2]=box[k,j,2]/im.size[0]*image_size\n",
    "            box1[k,j,3]=box[k,j,3]/im.size[1]*image_size\n",
    "            if box1[k,j,0]>image_size:\n",
    "                box1[k,j,0]=image_size\n",
    "            elif box1[k,j,0]<0:\n",
    "                box1[k,j,0]=0\n",
    "            if box1[k,j,1]>image_size:\n",
    "                box1[k,j,1]=image_size\n",
    "            elif box1[k,j,1]<0:\n",
    "                box1[k,j,1]=0\n",
    "            if box1[k,j,2]>image_size:\n",
    "                box1[k,j,2]=image_size\n",
    "            elif box1[k,j,2]<0:\n",
    "                box1[k,j,2]=0\n",
    "            if box1[k,j,3]>image_size:\n",
    "                box1[k,j,3]=image_size\n",
    "            elif box1[k,j,3]<0:\n",
    "                box1[k,j,3]=0\n",
    "        dataset[k]=new_data\n",
    "    \n",
    "    \n",
    "    return dataset,box1\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "start=time.time()\n",
    "strain_dataset,train_box=loadpics(train_pic,trainbox)\n",
    "end=time.time()\n",
    "print(end-start)\n",
    "\n",
    "start=time.time()\n",
    "stest_dataset,test_box=loadpics(test_pic,testbox)\n",
    "end=time.time()\n",
    "print(end-start)\n",
    "\n",
    "start=time.time()\n",
    "my_dataset,my_box=loadpics(my_pic,my_box)\n",
    "end=time.time()\n",
    "print(end-start)\n",
    "\n",
    "print('success')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Create a pickle file to store all data\"\"\"\n",
    "pickle_file='SVHN_alldata.pickle'\n",
    "\n",
    "try:\n",
    "    f=open(pickle_file,'wb')\n",
    "    save={\n",
    "        'train_dataset': strain_dataset,\n",
    "        'train_label': trainlabel,\n",
    "        'train_box': train_box,\n",
    "        'test_dataset': stest_dataset,\n",
    "        'test_label': testlabel,\n",
    "        'test_box': test_box,\n",
    "        'my_dataset': my_dataset,\n",
    "        'my_label':my_label,\n",
    "        'my_box':my_box,\n",
    "    }\n",
    "    pickle.dump(save,f,pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "    print('success')\n",
    "except Exception as e:\n",
    "    print('unable to save')\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
